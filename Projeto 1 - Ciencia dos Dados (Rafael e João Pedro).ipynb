{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Jo√£o Pedro Pereira Silva Marques de Oliveira\n",
    "\n",
    "Nome: Rafael Alves Madar√°s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas e o arquivo de base de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo coca cola.xlsx, tudo certo para prosseguir com o projeto!\n"
     ]
    }
   ],
   "source": [
    "filename = 'coca cola.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com o projeto!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>esse tic tac de coca cola √© bom dms pqp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>povo aq de casa t√£o tudo viciados em coca cola...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@mariano_mem acho que coca cola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevancia\n",
       "0            esse tic tac de coca cola √© bom dms pqp           1\n",
       "1  povo aq de casa t√£o tudo viciados em coca cola...           1\n",
       "2                    @mariano_mem acho que coca cola           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino = pd.read_excel(filename)\n",
    "treino.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@steffauxx la no jk com uma body piercing perf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>do nada uma puta vontade de tomar uma coca-col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>saudades de quando eu n√£o ligava pra esse tipo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevancia\n",
       "0  @steffauxx la no jk com uma body piercing perf...           0\n",
       "1  do nada uma puta vontade de tomar uma coca-col...           1\n",
       "2  saudades de quando eu n√£o ligava pra esse tipo...           1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "teste.drop(\"Unnamed: 2\",inplace=True,axis=1)\n",
    "teste.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a realiza√ß√£o desse projeto, tivemos o objetivo de escolher um produto e analisar diversos tweets sobre o mesmo, classificando-os como \"relevantes\" ou \"irrelevantes\" e montar um classificador autom√°tico de tweets. Para tal, o produto escolhido foi o mais famoso refrigerante do mundo: a Coca-Cola. Sabendo da grande fama da marca, era √≥bvio que haveria diversos tweets contendo seu nome. Portanto, foram utilizados os seguintes crit√©rios para a realiza√ß√£o da classifica√ß√£o dos tweets: \n",
    "\n",
    "- Relevantes(1): Tweets que continham o nome da marca sendo utilizado com refer√™ncia direta ao pr√≥prio produto, ou express√µes de cunho positivo ou negativo que agregassem valor √† marca.\n",
    "\n",
    "\n",
    "- Irrelevantes(0): Tweets que continham o nome da marca, mas n√£o faziam refer√™ncia direta ao pr√≥prio produto, nem agregavam valor √† ela, ou que continham o nome inserido numa frase sem contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√µes utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o que define emojis como emoji\n",
    "def emoji(s):\n",
    "    return s in UNICODE_EMOJI\n",
    "\n",
    "# fun√ß√£o que adiciona espa√ßo entre emojis/ emoji e palavra\n",
    "def adiciona_espaco_emoji(text):\n",
    "    return ''.join(' ' + char + ' 'if emoji(char) else char for char in text).strip()\n",
    "\n",
    "# fun√ß√£o que filtra o texto e retira as pontua√ß√µes indesejadas\n",
    "def tirar_pont(text):\n",
    "    punctuation = '[!-.:?;\"\\n\"()''\"\",_%$‡©≠ìÇÉ\\‚ÄîÔπ¢◊Ñ‚Ä∫„Éº|‚Ä¶/¬ª‚Äì]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# fun√ß√£o que filtra o texto e retira os links indesejados\n",
    "def tirar_link(text):\n",
    "    link = r'http[^\\s]*'    \n",
    "    pattern = re.compile(link)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# fun√ß√£o que filtra o texto e retira os espa√ßos indesejados\n",
    "def tirar_esp(text):\n",
    "    esp2 = '  '\n",
    "    pattern = re.compile(esp2)\n",
    "    text_subbed = re.sub(esp2, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# fun√ß√£o com todos os filtors anteriores\n",
    "def filtros(texto):\n",
    "    parte_1 = texto.lower()\n",
    "    parte_2 = tirar_link(parte_1)\n",
    "    parte_3 = tirar_pont(parte_2)\n",
    "    parte_4 = tirar_esp(parte_3)\n",
    "    return adiciona_espaco_emoji(parte_4)\n",
    "\n",
    "# fun√ß√£o que transforma texto em uma unica string\n",
    "def transforma_str(texto):\n",
    "    string = str()\n",
    "    for i in texto:\n",
    "        string +=' '+i\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obten√ß√£o das vari√°veis necess√°rias para criar o classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari√°veis gerais do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma a base de dados (treino) em vari√°vel categ√≥rica e define os nomes\n",
    "treino[\"Relevancia\"] = treino[\"Relevancia\"].astype('category')\n",
    "treino[\"Relevancia\"].cat.categories = [\"Irrelevante\",\"Relevante\"]\n",
    "\n",
    "# transforma a base de dados em uma string\n",
    "treino_str = transforma_str(treino['Treinamento'])\n",
    "\n",
    "# implementa√ß√£o dos filtros na string da base de dados\n",
    "texto_espaco_emoji = filtros(treino_str)\n",
    "\n",
    "# vari√°veis necess√°rias para o smoothing\n",
    "# Numero de palavras potencialmente existentes\n",
    "V = 10e5\n",
    "\n",
    "# \"bonus\" na contagem da palavra\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari√°veis de tweets relevantes do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie do Pandas dos tweets relevantes\n",
    "relevante = treino['Relevancia'] == \"Relevante\"\n",
    "\n",
    "# tabela com os tweets relevantes\n",
    "tweets_relevantes = treino.loc[relevante,:]\n",
    "\n",
    "# transforma em uma unica string os tweets relevantes\n",
    "treino_str_relevante = transforma_str(tweets_relevantes[\"Treinamento\"])\n",
    "\n",
    "# filtra string dos tweets relevantes\n",
    "str_clean_tweets_r = filtros(treino_str_relevante)\n",
    "\n",
    "# cria uma lista com cada termo da string dos tweets relevantes\n",
    "palavras_r = str_clean_tweets_r.split()\n",
    "\n",
    "# transforma tweets relevantes em serie do Pandas\n",
    "treinamento_r = pd.Series(palavras_r)\n",
    "\n",
    "\n",
    "# cria lista com cada tweet relevante\n",
    "lista_relevante = []\n",
    "for i in tweets_relevantes[\"Treinamento\"]:\n",
    "    lista_relevante.append(filtros(i))\n",
    "    \n",
    "\n",
    "#Frequencia absoluta das palavras relevantes e sua soma\n",
    "FR_r = treinamento_r.value_counts()\n",
    "soma_r = sum(FR_r)\n",
    "\n",
    "\n",
    "# P(palavra|relevante)\n",
    "prob_palavra_dado_r = (FR_r + alpha)/(soma_r + V*alpha)\n",
    "\n",
    "\n",
    "# P(tweet|relevante) \n",
    "# em uma lista (ordem da lista = ordem dos tweets)\n",
    "lista_r = []\n",
    "for tweet in lista_relevante:\n",
    "    prob_f_r = log(treino[\"Relevancia\"].value_counts(True)[1])\n",
    "    for palavra in tweet.split():\n",
    "        if palavra in prob_palavra_dado_r:\n",
    "            prob_f_r += log(prob_palavra_dado_r[palavra])\n",
    "        else:\n",
    "            prob_f_r += log(alpha/soma_r + V*alpha)         \n",
    "    lista_r.append(prob_f_r)\n",
    "\n",
    "# Dicion√°rio[tweet_relevante] = P(tweet|relevante)    \n",
    "dic_relevante = {} \n",
    "for i in range(len(lista_relevante)):\n",
    "    dic_relevante[lista_relevante[i]] = lista_r[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari√°veis de tweets irrelevantes do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie do Pandas dos tweets irrelevantes\n",
    "irrelevante = treino[\"Relevancia\"] == \"Irrelevante\"\n",
    "\n",
    "# tabela com tweets irrelevantes\n",
    "tweets_irrelevantes = treino.loc[irrelevante,:]\n",
    "\n",
    "# transforma em uma unica string os tweets irrelevantes\n",
    "treino_str_irrelevante = transforma_str(tweets_irrelevantes[\"Treinamento\"])\n",
    "\n",
    "# filtra string com os tweets irrelevantes\n",
    "str_clean_tweets_i = filtros(treino_str_irrelevante)\n",
    "\n",
    "# cria uma lista com cada termo da string dos tweets irrelevante\n",
    "palavras_i = str_clean_tweets_i.split()\n",
    "\n",
    "# transforma tweets irrelevantes em serie do Pandas\n",
    "treinamento_i = pd.Series(palavras_i)\n",
    "\n",
    "# cria lista com cada tweet irrelevante\n",
    "lista_irrelevante = []\n",
    "for i in tweets_irrelevantes[\"Treinamento\"]:\n",
    "    lista_irrelevante.append(filtros(i))\n",
    "\n",
    "#Frequencia absoluta das palavras irrelevantes e sua soma\n",
    "FR_i = treinamento_i.value_counts()\n",
    "soma_i = sum(FR_i)\n",
    "\n",
    "# P(palavra|irrelevante)\n",
    "prob_palavra_dado_i = (FR_i + alpha)/(soma_i + V*alpha)\n",
    "\n",
    "# P(tweet|irrelevante)\n",
    "# em uma lista (ordem da lista = ordem dos tweets)\n",
    "lista_i = []\n",
    "for tweet in lista_irrelevante:\n",
    "    prob_f_i = log(treino[\"Relevancia\"].value_counts(True)[0])\n",
    "    for palavra in tweet.split():\n",
    "        if palavra in prob_palavra_dado_i:\n",
    "            prob_f_i += log(prob_palavra_dado_i[palavra])\n",
    "        else:\n",
    "            prob_f_i += log(alpha/soma_i + V*alpha)       \n",
    "    lista_i.append(prob_f_i)\n",
    "\n",
    "# Dicion√°rio[tweet_irrelevante] = P(tweet|irrelevante)\n",
    "dic_irrelevante = {}    \n",
    "for i in range(len(lista_irrelevante)):\n",
    "    dic_irrelevante[lista_irrelevante[i]] = lista_i[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cria dicion√°rio no formato: dic_resultado[tweet] = relev√¢ncia_do_tweet\n",
    "dic_resultado = {}\n",
    "for tweet_r, tweet_r_prob in dic_relevante.items(): \n",
    "    for tweet_i,tweet_i_prob in dic_irrelevante.items():\n",
    "        \n",
    "        if tweet_r == tweet_i: \n",
    "            if tweet_r_prob > tweet_i_prob:\n",
    "                dic_resultado[tweet_r] = \"relevante\"   \n",
    "            else: \n",
    "                dic_resultado[tweet_i] = \"irrelevante\" \n",
    "                \n",
    "        if tweet_r != tweet_i and tweet_r not in dic_resultado:\n",
    "            dic_resultado[tweet_r] = \"relevante\"   \n",
    "            \n",
    "        if tweet_r != tweet_i and tweet_i not in dic_resultado:\n",
    "            dic_resultado[tweet_i] = \"irrelevante\"\n",
    "\n",
    "# cria lista com todos os tweets filtrados \n",
    "lista_tweets_total = []\n",
    "for i in treino[\"Treinamento\"]:\n",
    "    lista_tweets_total.append(filtros(i))\n",
    "\n",
    "# transforma lista_tweets_total em lista do pandas e adiciona ao DataFrame \"treino\"\n",
    "Treinamento_filtrado_NB = pd.Series(lista_tweets_total)\n",
    "treino['Treinamento_filtrado_NB'] = Treinamento_filtrado_NB\n",
    "        \n",
    "# dicion√°rio final no formato: dic_final[tweet] = relevancia \n",
    "# esse dicion√°rio foi utilizado para deixar o dic_resultado na ordem da lista_tweets_total\n",
    "dic_final = {}\n",
    "for tweet in lista_tweets_total:\n",
    "    for tweet_resultado, relevancia in dic_resultado.items():\n",
    "        if tweet_resultado == tweet:\n",
    "            dic_final[tweet] = relevancia \n",
    "\n",
    "# lista com a relevancia de cada tweet na ordem do respectivo tweets na lista_tweets_total\n",
    "lista_relevancia = []\n",
    "for relevancia in dic_final.values():\n",
    "    lista_relevancia.append(relevancia)\n",
    "\n",
    "# adiciona ao DataFrame \"treino\" a tabela \"Relevancia_NB\"\n",
    "Relevancia_NB = pd.Series(lista_relevancia)\n",
    "treino[\"Relevancia_NB\"] = Relevancia_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela de compara√ß√£o entre a porcentagem de relev√¢ncia dos tweets determinados previamente (pelo excel) e porcentagem de relev√¢ncia dos tweets determinados pelo nosso classificador, com base na planilha de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relevancia_NB</th>\n",
       "      <th>irrelevante</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>0.140468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relevancia_NB  irrelevante  relevante\n",
       "Relevancia                           \n",
       "Irrelevante       0.367893   0.140468\n",
       "Relevante         0.143813   0.347826"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_comparacao_treino = pd.crosstab(treino[\"Relevancia\"],treino[\"Relevancia_NB\"],normalize=True)\n",
    "tabela_comparacao_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidades por categoria  (Treinamento)\n",
    "#### Probabilidade de verdadeiros positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(verdadeiros_positivos) =  34.78261 %\n"
     ]
    }
   ],
   "source": [
    "P_VP = ((tabela_comparacao_treino.iloc[1,1])*100).round(5)\n",
    "print(\"P(verdadeiros_positivos) = \",P_VP,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de verdadeiros negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(verdadeiros_negativos) =  14.38127 %\n"
     ]
    }
   ],
   "source": [
    "P_VN = ((tabela_comparacao_treino.iloc[1,0])*100).round(5)\n",
    "print(\"P(verdadeiros_negativos) = \",P_VN,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de falsos positivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(falsos_positivoss) =  36.7893 %\n"
     ]
    }
   ],
   "source": [
    "P_FP = ((tabela_comparacao_treino.iloc[0,0])*100).round(5)\n",
    "print(\"P(falsos_positivoss) = \",P_FP,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de falsos negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(falsos_negativos) =  14.04682 %\n"
     ]
    }
   ],
   "source": [
    "P_FN = ((tabela_comparacao_treino.iloc[0,1])*100).round(5)\n",
    "print(\"P(falsos_negativos) = \",P_FN,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testear o seu classificador com a base de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# transforma a base de dados (teste) em vari√°vel categ√≥rica e define os nomes\n",
    "teste[\"Relevancia\"] = teste[\"Relevancia\"].astype('category')\n",
    "teste[\"Relevancia\"].cat.categories = [\"Irrelevante\",\"Relevante\"]\n",
    "\n",
    "# cria lista com todos os tweets filtrados\n",
    "lista_tweets_teste = []\n",
    "for i in teste[\"Teste\"]:\n",
    "    lista_tweets_teste.append(filtros(i))\n",
    "\n",
    "# transforma lista_tweets_teste em lista do pandas e adiciona ao DataFrame \"teste\"\n",
    "Teste_filtrado_NB_teste = pd.Series(lista_tweets_teste)\n",
    "teste['Teste_filtrado'] = Teste_filtrado_NB_teste\n",
    "        \n",
    "# dicion√°rio final no formato: dic_final[tweet] = relevancia \n",
    "dic_final_teste = {}\n",
    "for tweet in lista_tweets_teste:\n",
    "    for tweet_resultado,relevancia in dic_resultado.items():\n",
    "        if tweet_resultado == tweet:\n",
    "            dic_final_teste[tweet] = relevancia \n",
    "            \n",
    "# lista com a relevancia de cada tweet na ordem do respectivo tweets na lista_tweets_total\n",
    "lista_relevancia_teste = []\n",
    "for relevancia in dic_final_teste.values():\n",
    "    lista_relevancia_teste.append(relevancia)\n",
    "    \n",
    "# adiciona ao DataFrame \"treino\" a tabela \"Relevancia_NB\"\n",
    "Relevancia_NB_teste = pd.Series(lista_relevancia)\n",
    "teste[\"Relevancia_NB\"] = Relevancia_NB_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Relevancia_NB</th>\n",
       "      <th>irrelevante</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Relevante</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Relevancia_NB  irrelevante  relevante\n",
       "Relevancia                           \n",
       "Irrelevante          0.240      0.190\n",
       "Relevante            0.295      0.275"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_comparacao = pd.crosstab(teste[\"Relevancia\"],teste[\"Relevancia_NB\"],normalize=True)\n",
    "tabela_comparacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidades por categoria  (teste)\n",
    "#### Probabilidade de verdadeiros positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(verdadeiros_positivos) =  27.5 %\n"
     ]
    }
   ],
   "source": [
    "P_VP = ((tabela_comparacao.iloc[1,1])*100).round(5)\n",
    "print(\"P(verdadeiros_positivos) = \",P_VP,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de verdadeiros negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(verdadeiros_negativos) =  29.5 %\n"
     ]
    }
   ],
   "source": [
    "P_VN = ((tabela_comparacao.iloc[1,0])*100).round(5)\n",
    "print(\"P(verdadeiros_negativos) = \",P_VN,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de falsos positivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(falsos_positivoss) =  24.0 %\n"
     ]
    }
   ],
   "source": [
    "P_FP = ((tabela_comparacao.iloc[0,0])*100).round(5)\n",
    "print(\"P(falsos_positivoss) = \",P_FP,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade de falsos negativos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(falsos_negativos) =  19.0 %\n"
     ]
    }
   ],
   "source": [
    "P_FN = ((tabela_comparacao.iloc[0,1])*100).round(5)\n",
    "print(\"P(falsos_negativos) = \",P_FN,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acur√°cia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acur√°cia do nosso classificador √© de  51.5 %.\n"
     ]
    }
   ],
   "source": [
    "acuracia = (tabela_comparacao.iloc[0,0]+tabela_comparacao.iloc[1,1])*100\n",
    "print(\"A acur√°cia do nosso classificador √© de \", acuracia,\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a planilha de treino (\"Treinamento\") e as no√ß√µes de probabilidade aprendidas em aula, montamos nosso classificador Naive-Bayes e o testamos. Para isso, utilizamos uma outra planilha, dessa vez com tweets diferentes da anterior: a planilha \"Teste\". Ao finalizar os testes, obtivemos as probabilidades indicadas acima. Com elas, √© poss√≠vel observar que o classficador n√£o √© muito eficiente e funciona um pouco melhor para os tweets relevantes do que para os irrelevantes. Tamb√©m obtivemos a acur√°cia total do classificador, que √© por volta de 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que s√≥ trabalhamos com duas categorias (\"irrelevante\" e \"relevante\"), √© impossivel afirmar com certeza o destino das mensagens que continham dupla nega√ß√£o ou sarcasmo que passaram pelo classificador. Para come√ßar, √© importante frisar que qualquer tweet que agregava valor ao produto foi classificado por n√≥s como relevante. Dado que as mensagens sarc√°sticas da base de treinamento em sua maioria agragavam valor ao nome da marca, muito provavelmente elas foram classificadas como relevantes, induzindo o classificador a colocar mais mensagens como ela nessa categoria, independente da inten√ß√£o do tweet. Para os tweets com dupla nega√ß√£o, seus destinos s√£o bem mais incertos, pois, como existe a ocorr√™ncia de palavras de sentido negativo mais de uma vez, o classificador acaba se confundindo com o real sentido do tweet, e assim classifica-o de forma incorreta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo com um classificador que tem um percentual de efici√™cia que se assemelha ao giro de uma moeda, ele ainda pode ter muita utilidade e ser muito mais eficiente. Com uma base de dados maior e mais precisa, as probabilidades dele classificar um tweet como relevante ou irrelevante, seriam muito mais pr√≥ximas da realidade. Al√©m disso, com mais tempo de desenvolvimento, seria poss√≠vel tornar o c√≥digo mais complexo ao adicionar novas funcionalidades. Dentre as quais podemos citar a import√¢ncia na ordem das palavras e o fato das palavras n√£o ocorrerem de forma independente no tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo que seja um classificador simples, o Naive-Bayes tem v√°rias funcionalidades e pode ser aplicado em diversas ocasi√µes. Uma delas, por exemplo, √© a organiza√ß√£o de uma caixa de entrada e emails, onde, atrav√©s do classificador, seria poss√≠vel categorizar os emails em spam e n√£o spam. Outra aplica√ß√£o poss√≠vel para o Naive-Bayes √© a identifica√ß√£o do assunto de uma not√≠cia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
